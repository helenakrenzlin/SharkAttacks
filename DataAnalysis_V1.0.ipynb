{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4681c0a3",
   "metadata": {},
   "source": [
    "#Shark attacks\n",
    "\n",
    "IMPORTING THE LIBRARIES AND THE DATA INTO A PANDAS DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1736910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#load the data into a pandas DataFrame\n",
    "df= pd.read_excel(\"GSAF5.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec5a7e",
   "metadata": {},
   "source": [
    "2. CLEANING THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63f7b6",
   "metadata": {},
   "source": [
    "2.1 IDENTIFYING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfd68194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal Y/N</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Point Plomber North of Port Macquarie</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Paul Zvirdinas</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>Minor cuts and abrasions</td>\n",
       "      <td>N</td>\n",
       "      <td>0830hrs</td>\n",
       "      <td>Bull shark</td>\n",
       "      <td>Bob Myatt GSAF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Dee Why</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>None reported damage to board</td>\n",
       "      <td>N</td>\n",
       "      <td>1145hrs</td>\n",
       "      <td>Bull shark</td>\n",
       "      <td>Andy Currie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>North Steyne</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Andre de Ruyter</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>Serious Leg injuries</td>\n",
       "      <td>N</td>\n",
       "      <td>1820hrs</td>\n",
       "      <td>5m shark species not determined</td>\n",
       "      <td>9 News: Bob Myatt GSAF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Nielsen Park Vaucluse Sydney Harbour</td>\n",
       "      <td>Jumping off rocks</td>\n",
       "      <td>Nico Antic</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>Serious leg injuries</td>\n",
       "      <td>Y</td>\n",
       "      <td>1620hrs</td>\n",
       "      <td>Bull shark</td>\n",
       "      <td>Bob Myatt GSAF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Avalon Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Paul Stanton</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>Puncture mark to left thumb</td>\n",
       "      <td>N</td>\n",
       "      <td>0540hrs</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Bob Myatt GSAF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Year        Type    Country State  \\\n",
       "0  20th January  2026.0  Unprovoked  Australia   NSW   \n",
       "1  19th January  2026.0  Unprovoked  Australia   NSW   \n",
       "2  19th January  2026.0  Unprovoked  Australia   NSW   \n",
       "3  18th January  2026.0  Unprovoked  Australia   NSW   \n",
       "4  10th January  2026.0  Unprovoked  Australia   NSW   \n",
       "\n",
       "                                Location           Activity             Name  \\\n",
       "0  Point Plomber North of Port Macquarie            Surfing   Paul Zvirdinas   \n",
       "1                                Dee Why            Surfing          Unknown   \n",
       "2                          North Steyne             Surfing  Andre de Ruyter   \n",
       "3   Nielsen Park Vaucluse Sydney Harbour  Jumping off rocks       Nico Antic   \n",
       "4                           Avalon Beach            Surfing     Paul Stanton   \n",
       "\n",
       "  Sex Age                         Injury Fatal Y/N     Time  \\\n",
       "0   M  39      Minor cuts and abrasions          N  0830hrs   \n",
       "1   M  11  None reported damage to board         N  1145hrs   \n",
       "2   M  27           Serious Leg injuries         N  1820hrs   \n",
       "3   M  12           Serious leg injuries         Y  1620hrs   \n",
       "4   M   ?    Puncture mark to left thumb         N  0540hrs   \n",
       "\n",
       "                          Species                   Source  pdf href formula  \\\n",
       "0                       Bull shark          Bob Myatt GSAF  NaN          NaN   \n",
       "1                       Bull shark             Andy Currie  NaN          NaN   \n",
       "2  5m shark species not determined  9 News: Bob Myatt GSAF  NaN          NaN   \n",
       "3                       Bull shark          Bob Myatt GSAF  NaN          NaN   \n",
       "4                          Unknown          Bob Myatt GSAF  NaN          NaN   \n",
       "\n",
       "  href Case Number Case Number.1  original order Unnamed: 21 Unnamed: 22  \n",
       "0  NaN         NaN           NaN             NaN         NaN         NaN  \n",
       "1  NaN         NaN           NaN             NaN         NaN         NaN  \n",
       "2  NaN         NaN           NaN             NaN         NaN         NaN  \n",
       "3  NaN         NaN           NaN             NaN         NaN         NaN  \n",
       "4  NaN         NaN           NaN             NaN         NaN         NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = None  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28b21de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7070, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking number of rows and columns in the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9313e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Year', 'Type', 'Country', 'State', 'Location', 'Activity',\n",
       "       'Name', 'Sex', 'Age', 'Injury', 'Fatal Y/N', 'Time', 'Species ',\n",
       "       'Source', 'pdf', 'href formula', 'href', 'Case Number', 'Case Number.1',\n",
       "       'original order', 'Unnamed: 21', 'Unnamed: 22'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checling the column names in the dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86974a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "View datatypes:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7070 entries, 0 to 7069\n",
      "Data columns (total 23 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Date            7070 non-null   object \n",
      " 1   Year            7068 non-null   float64\n",
      " 2   Type            7052 non-null   object \n",
      " 3   Country         7020 non-null   object \n",
      " 4   State           6583 non-null   object \n",
      " 5   Location        6503 non-null   object \n",
      " 6   Activity        6485 non-null   object \n",
      " 7   Name            6851 non-null   object \n",
      " 8   Sex             6491 non-null   object \n",
      " 9   Age             4075 non-null   object \n",
      " 10  Injury          7035 non-null   object \n",
      " 11  Fatal Y/N       6509 non-null   object \n",
      " 12  Time            3543 non-null   object \n",
      " 13  Species         3939 non-null   object \n",
      " 14  Source          7050 non-null   object \n",
      " 15  pdf             6799 non-null   object \n",
      " 16  href formula    6794 non-null   object \n",
      " 17  href            6796 non-null   object \n",
      " 18  Case Number     6798 non-null   object \n",
      " 19  Case Number.1   6797 non-null   object \n",
      " 20  original order  6799 non-null   float64\n",
      " 21  Unnamed: 21     1 non-null      object \n",
      " 22  Unnamed: 22     2 non-null      object \n",
      "dtypes: float64(2), object(21)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date               object\n",
       "Year              float64\n",
       "Type               object\n",
       "Country            object\n",
       "State              object\n",
       "Location           object\n",
       "Activity           object\n",
       "Name               object\n",
       "Sex                object\n",
       "Age                object\n",
       "Injury             object\n",
       "Fatal Y/N          object\n",
       "Time               object\n",
       "Species            object\n",
       "Source             object\n",
       "pdf                object\n",
       "href formula       object\n",
       "href               object\n",
       "Case Number        object\n",
       "Case Number.1      object\n",
       "original order    float64\n",
       "Unnamed: 21        object\n",
       "Unnamed: 22        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing the data types of each column \n",
    "\n",
    "print(\"\\nView datatypes:\\n\")\n",
    "df.info()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99764856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "View descriptive statistics (numerical columns):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>7068.0</td>\n",
       "      <td>1935.953311</td>\n",
       "      <td>270.740135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original order</th>\n",
       "      <td>6799.0</td>\n",
       "      <td>3401.152081</td>\n",
       "      <td>1963.076319</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1701.5</td>\n",
       "      <td>3401.0</td>\n",
       "      <td>5100.5</td>\n",
       "      <td>6802.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count         mean          std  min     25%     50%     75%  \\\n",
       "Year            7068.0  1935.953311   270.740135  0.0  1948.0  1986.0  2010.0   \n",
       "original order  6799.0  3401.152081  1963.076319  2.0  1701.5  3401.0  5100.5   \n",
       "\n",
       "                   max  \n",
       "Year            2026.0  \n",
       "original order  6802.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get descriptive stats for numerical columns \n",
    "print(\"\\nView descriptive statistics (numerical columns):\\n\")\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb41ae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count missing values in each column:\n",
      "\n",
      "Date                 0\n",
      "Year                 2\n",
      "Type                18\n",
      "Country             50\n",
      "State              487\n",
      "Location           567\n",
      "Activity           585\n",
      "Name               219\n",
      "Sex                579\n",
      "Age               2995\n",
      "Injury              35\n",
      "Fatal Y/N          561\n",
      "Time              3527\n",
      "Species           3131\n",
      "Source              20\n",
      "pdf                271\n",
      "href formula       276\n",
      "href               274\n",
      "Case Number        272\n",
      "Case Number.1      273\n",
      "original order     271\n",
      "Unnamed: 21       7069\n",
      "Unnamed: 22       7068\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count missing values in each column\n",
    "print(\"\\nCount missing values in each column:\\n\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1954eec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique values for each column:\n",
      "Date              6110\n",
      "Year               261\n",
      "Type                13\n",
      "Country            251\n",
      "State              944\n",
      "Location          4616\n",
      "Activity          1610\n",
      "Name              5789\n",
      "Sex                 10\n",
      "Age                251\n",
      "Injury            4183\n",
      "Fatal Y/N           12\n",
      "Time               473\n",
      "Species           1737\n",
      "Source            5401\n",
      "pdf               6789\n",
      "href formula      6784\n",
      "href              6776\n",
      "Case Number       6777\n",
      "Case Number.1     6775\n",
      "original order    6797\n",
      "Unnamed: 21          1\n",
      "Unnamed: 22          2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# amount of unique values for each column\n",
    "unique_counts = df.nunique()\n",
    "print(\"\\nNumber of unique values for each column:\")\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d4eba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Year                 2\n",
       "Type                18\n",
       "Country             50\n",
       "State              487\n",
       "Location           567\n",
       "Activity           585\n",
       "Name               219\n",
       "Sex                579\n",
       "Age               2995\n",
       "Injury              35\n",
       "Fatal Y/N          561\n",
       "Time              3527\n",
       "Species           3131\n",
       "Source              20\n",
       "pdf                271\n",
       "href formula       276\n",
       "href               274\n",
       "Case Number        272\n",
       "Case Number.1      273\n",
       "original order     271\n",
       "Unnamed: 21       7069\n",
       "Unnamed: 22       7068\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code for counting NaN values in each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3df0715a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 activities are: \n",
      "Activity\n",
      "Surfing                                          1146\n",
      "Swimming                                         1011\n",
      "Fishing                                           494\n",
      "Spearfishing                                      391\n",
      "Wading                                            178\n",
      "                                                 ... \n",
      "Floating on a small orange raft                     1\n",
      "Filming & feeding captive sharks                    1\n",
      "Attempting to drive shark away from the beach       1\n",
      "Spearfishing / scuba diving                         1\n",
      "Wreck of  large double sailing canoe                1\n",
      "Name: count, Length: 1610, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#code for counting unique values in the \"Activity\" column and then printing the top 5 most common activities\n",
    "activities_count = df[\"Activity\"].value_counts()\n",
    "top_five_sports = {activity: count for activity, count in activities_count.nlargest(5).items()}\n",
    "print(f\"The top 5 activities are: \\n{activities_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ba9884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Surfing', 'Jumping off rocks', 'Snorkeling', ...,\n",
       "       'Crew swimming alongside their anchored ship',\n",
       "       '4 men were bathing', 'Wreck of  large double sailing canoe'],\n",
       "      shape=(1611,), dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#too many unique values, so we need to clean and standardize the data\n",
    "df[\"Activity\"].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79154210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 injuries are: \n",
      "Injury\n",
      "FATAL                                                                   863\n",
      "Foot bitten                                                             100\n",
      "Survived                                                                 97\n",
      "No injury                                                                85\n",
      "Leg bitten                                                               81\n",
      "                                                                       ... \n",
      "Right wrist  & left arm lacerated                                         1\n",
      "Puncture wounds on shin                                                   1\n",
      "Left hand, foot severed &  left calf & arm bitten                         1\n",
      "Single puncture wound on the foot                                         1\n",
      "FATAL. \"Shark bit him in half, carrying away the lower extremities\"       1\n",
      "Name: count, Length: 4183, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#code for counting unique values in the \"Injury\" column and then printing the top 5 most common injuries\n",
    "injury_count = df[\"Injury\"].value_counts()\n",
    "top_five_inuries = {injury: count for injury, count in injury_count.nlargest(5).items()}\n",
    "print(f\"The top 5 injuries are: \\n{injury_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10d8b87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Unprovoked             5221\n",
       "Provoked                642\n",
       "Invalid                 552\n",
       "Watercraft              355\n",
       "Sea Disaster            242\n",
       "Questionable             26\n",
       "Boat                      7\n",
       " Provoked                 2\n",
       "unprovoked                1\n",
       "?                         1\n",
       "Unconfirmed               1\n",
       "Unverified                1\n",
       "Under investigation       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code for counting unique values in the \"Type\" column\n",
    "type_count = df[\"Type\"].value_counts()\n",
    "type_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d400512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "M        5670\n",
       "F         808\n",
       "M           4\n",
       "F           2\n",
       "N           2\n",
       " M          1\n",
       "m           1\n",
       "lli         1\n",
       "M x 2       1\n",
       ".           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code for counting unique values in the sex column\n",
    "sex_count = df[\"Sex\"].value_counts()\n",
    "sex_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47002cee",
   "metadata": {},
   "source": [
    "DATA CLEANING & STANDARDADIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a36a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Point Plomber North of Port Macquarie</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Paul Zvirdinas</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>Minor cuts and abrasions</td>\n",
       "      <td>Bull shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Dee Why</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>None reported damage to board</td>\n",
       "      <td>Bull shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>North Steyne</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Andre de Ruyter</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>Serious Leg injuries</td>\n",
       "      <td>5m shark species not determined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Year        Type    Country State  \\\n",
       "0  20th January  2026.0  Unprovoked  Australia   NSW   \n",
       "1  19th January  2026.0  Unprovoked  Australia   NSW   \n",
       "2  19th January  2026.0  Unprovoked  Australia   NSW   \n",
       "\n",
       "                                Location Activity             Name Sex Age  \\\n",
       "0  Point Plomber North of Port Macquarie  Surfing   Paul Zvirdinas   M  39   \n",
       "1                                Dee Why  Surfing          Unknown   M  11   \n",
       "2                          North Steyne   Surfing  Andre de Ruyter   M  27   \n",
       "\n",
       "                          Injury                         Species   \n",
       "0      Minor cuts and abrasions                        Bull shark  \n",
       "1  None reported damage to board                       Bull shark  \n",
       "2           Serious Leg injuries  5m shark species not determined  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove multiple columns:\n",
    "df = df.drop(['Source', 'pdf', 'href formula', 'href', 'Case Number', 'Case Number.1','original order', 'Unnamed: 21', 'Unnamed: 22','Fatal Y/N', 'Time'], axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c4e8f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           0\n",
       "Year           2\n",
       "Type          14\n",
       "Country       43\n",
       "State        403\n",
       "Location     475\n",
       "Activity       0\n",
       "Name         157\n",
       "Sex          425\n",
       "Age         2572\n",
       "Injury        19\n",
       "Species     2788\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop rows with missing values in the \"Activity\" column and then count the number of missing values in each column again to confirm that the rows have been removed\n",
    "df.dropna(subset=['Activity'], inplace= True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a78084da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>attack_type</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>activity</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>injury</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Point Plomber North of Port Macquarie</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Paul Zvirdinas</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>Minor cuts and abrasions</td>\n",
       "      <td>Bull shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Dee Why</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>None reported damage to board</td>\n",
       "      <td>Bull shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>North Steyne</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Andre de Ruyter</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>Serious Leg injuries</td>\n",
       "      <td>5m shark species not determined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Nielsen Park Vaucluse Sydney Harbour</td>\n",
       "      <td>Jumping off rocks</td>\n",
       "      <td>Nico Antic</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>Serious leg injuries</td>\n",
       "      <td>Bull shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10th January</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Avalon Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Paul Stanton</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>Puncture mark to left thumb</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date    year attack_type    country state  \\\n",
       "0  20th January  2026.0  Unprovoked  Australia   NSW   \n",
       "1  19th January  2026.0  Unprovoked  Australia   NSW   \n",
       "2  19th January  2026.0  Unprovoked  Australia   NSW   \n",
       "3  18th January  2026.0  Unprovoked  Australia   NSW   \n",
       "4  10th January  2026.0  Unprovoked  Australia   NSW   \n",
       "\n",
       "                                location           activity             name  \\\n",
       "0  Point Plomber North of Port Macquarie            Surfing   Paul Zvirdinas   \n",
       "1                                Dee Why            Surfing          Unknown   \n",
       "2                          North Steyne             Surfing  Andre de Ruyter   \n",
       "3   Nielsen Park Vaucluse Sydney Harbour  Jumping off rocks       Nico Antic   \n",
       "4                           Avalon Beach            Surfing     Paul Stanton   \n",
       "\n",
       "  sex age                         injury                          species  \n",
       "0   M  39      Minor cuts and abrasions                        Bull shark  \n",
       "1   M  11  None reported damage to board                       Bull shark  \n",
       "2   M  27           Serious Leg injuries  5m shark species not determined  \n",
       "3   M  12           Serious leg injuries                       Bull shark  \n",
       "4   M   ?    Puncture mark to left thumb                          Unknown  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean and standardize the data by converting all text to lowercase, removing leading and trailing whitespace, and replacing spaces with underscores in the column names\n",
    "df.rename(columns= lambda x: x.lower().strip().replace(\" \", \"_\").replace (\":\",\" \").replace(\".\" , \" \"), inplace=True)\n",
    "df.rename(columns={\"type\": \"attack_type\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40179dfd",
   "metadata": {},
   "source": [
    "YEAR FILTERING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28f4b3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>attack_type</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>activity</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>injury</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20th January</td>\n",
       "      <td>2026</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Point Plomber North of Port Macquarie</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Paul Zvirdinas</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>Minor cuts and abrasions</td>\n",
       "      <td>Bull shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19th January</td>\n",
       "      <td>2026</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Dee Why</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>None reported damage to board</td>\n",
       "      <td>Bull shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19th January</td>\n",
       "      <td>2026</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>North Steyne</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Andre de Ruyter</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>Serious Leg injuries</td>\n",
       "      <td>5m shark species not determined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18th January</td>\n",
       "      <td>2026</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Nielsen Park Vaucluse Sydney Harbour</td>\n",
       "      <td>Jumping off rocks</td>\n",
       "      <td>Nico Antic</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>Serious leg injuries</td>\n",
       "      <td>Bull shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10th January</td>\n",
       "      <td>2026</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Avalon Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Paul Stanton</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>Puncture mark to left thumb</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  year attack_type    country state  \\\n",
       "0  20th January  2026  Unprovoked  Australia   NSW   \n",
       "1  19th January  2026  Unprovoked  Australia   NSW   \n",
       "2  19th January  2026  Unprovoked  Australia   NSW   \n",
       "3  18th January  2026  Unprovoked  Australia   NSW   \n",
       "4  10th January  2026  Unprovoked  Australia   NSW   \n",
       "\n",
       "                                location           activity             name  \\\n",
       "0  Point Plomber North of Port Macquarie            Surfing   Paul Zvirdinas   \n",
       "1                                Dee Why            Surfing          Unknown   \n",
       "2                          North Steyne             Surfing  Andre de Ruyter   \n",
       "3   Nielsen Park Vaucluse Sydney Harbour  Jumping off rocks       Nico Antic   \n",
       "4                           Avalon Beach            Surfing     Paul Stanton   \n",
       "\n",
       "  sex age                         injury                          species  \n",
       "0   M  39      Minor cuts and abrasions                        Bull shark  \n",
       "1   M  11  None reported damage to board                       Bull shark  \n",
       "2   M  27           Serious Leg injuries  5m shark species not determined  \n",
       "3   M  12           Serious leg injuries                       Bull shark  \n",
       "4   M   ?    Puncture mark to left thumb                          Unknown  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean and standardize the data in the \"year\" column to only include years from 2000 to 2026 and convert the data type from float to integer, while also handling any missing values by filling them with 0 before converting to integer\n",
    "\n",
    "df2 = df[(df ['year'] >= 2000) & (df['year'] < 2027)].copy()\n",
    "df2[\"year\"] = df2[\"year\"].fillna(0).astype(int)\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f53d57d",
   "metadata": {},
   "source": [
    "SEX (Missing - what will we do with the unknown values?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03e89192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'F' 'F ' 'M ' nan 'm' 'lli']\n",
      "['M' 'F' 'unknown']\n"
     ]
    }
   ],
   "source": [
    "#clean and standardize the data in the \"sex\" column by removing leading and trailing whitespace, converting all text to lowercase, and replacing any non-standard values with \"unknown\"\n",
    "print(df2['sex'].unique())\n",
    "df2['sex'] = df2['sex'].str.strip()\n",
    "\n",
    "sex_mapping = {\n",
    "    \"N\": np.nan,\n",
    "    \"lli\": np.nan,\n",
    "    \".\": np.nan,\n",
    "    \"M x 2\": \"M\",\n",
    "    \"m\": \"M\",\n",
    "    \"f\": \"F\"\n",
    "}\n",
    "df2['sex'] = df2['sex'].replace(sex_mapping)\n",
    "df2['sex']= df2['sex'].fillna('unknown')\n",
    "print(df2['sex'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0c4150",
   "metadata": {},
   "source": [
    "ATTACK_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57737b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unprovoked' 'Provoked' 'Questionable' 'unprovoked' ' Provoked'\n",
      " 'Watercraft' 'Sea Disaster' '?' nan 'Unconfirmed' 'Unverified' 'Invalid'\n",
      " 'Under investigation' 'Boat']\n",
      "['Unprovoked' 'Provoked' 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "#clean and standardize the data in the \"type\" column by removing leading and trailing whitespace, converting all text to lowercase, and replacing any non-standard values with \"unknown\"\n",
    "df[\"attack_type\"].unique()\n",
    "print(df['attack_type'].unique())\n",
    "df['attack_type'] = df['attack_type'].str.strip()\n",
    "type_mapping = {\n",
    "    \"Unprovoked\": \"Unprovoked\",\n",
    "    \"Provoked\": \"Provoked\",\n",
    "    \"Boating\": np.nan,\n",
    "    \"Invalid\": np.nan,\n",
    "    \"Sea Disaster\": \"Unprovoked\",\n",
    "    \"?\":  np.nan,\n",
    "    \"Boat\": np.nan,\n",
    "    \"Invalid \": np.nan,\n",
    "    \"Questionable\": np.nan,\n",
    "    \"Unconfirmed\": np.nan,\n",
    "    \"Unverified\": np.nan,\n",
    "    \"Under investigation\": np.nan,\n",
    "    \"Watercraft\": np.nan,\n",
    "    \"unprovoked\": \"Unprovoked\",\n",
    "    \"Invalid Incident\": np.nan,\n",
    "    \"Invalid \": np.nan\n",
    "}\n",
    "df['attack_type'] = df['attack_type'].replace(type_mapping)\n",
    "df['attack_type']= df['attack_type'].fillna('Unknown')\n",
    "print(df['attack_type'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c6052",
   "metadata": {},
   "source": [
    "ACTIVITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "835dfcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Surfing', 'Jumping off rocks', 'Snorkeling', 'Scuba Diving',\n",
       "       'SCUBA Diving', 'Swimming', 'Freeing trapped shark',\n",
       "       'Foil Boarding', 'Fishing', 'Swimming with sharks',\n",
       "       'Fishing/swimming', 'Diving-Tagging sharks', 'Spearfishing',\n",
       "       'Wading', 'Kayaking ', 'Surfing (Hydrofoiling)', 'Diving',\n",
       "       'Paddling', 'Rescuing female companion ', 'snorkeling',\n",
       "       'Undisclosed', 'Kayaking', 'Fishing was pulled of boat by shark',\n",
       "       'Bathing', 'Disappeared whilst diving remains found in shark',\n",
       "       'Diving for shellfish', 'Swimming - jumped off yacht',\n",
       "       'Swimming - Diving ', 'Diving into Water',\n",
       "       'Playing football in the water',\n",
       "       'Unconfirmed Possibly swimming near the boat harbour',\n",
       "       'Swimming ocean training ', 'Military ocean training',\n",
       "       'snorkelling', 'Freediving',\n",
       "       'Jumpinf from dock to boat acidentally fell into water at marina',\n",
       "       'Free diving', 'Paddle boarding', 'Scuba diving',\n",
       "       'On a round-the-world expedition', 'Kayak fishing',\n",
       "       'Towing a dead whale out to sea', 'Boogie boarding', 'Sitting',\n",
       "       'Watching the sardine run', 'Standing', 'Filming', 'Kite surfing',\n",
       "       'Jumped overboard', 'Shark Feeding', 'Diving for crayfish',\n",
       "       'Windsurfing', 'Kite-Surfing', 'Surf-sking',\n",
       "       'Diving with  surface-supplied air', 'Spearishing',\n",
       "       'Snorkeling at Shark Feeding site', 'Diving/Shark Feeding',\n",
       "       'Surf skiing ', 'Shipwreck', 'Swimming  or Snorkeling',\n",
       "       'Paddleboarding', 'Lobstering', 'Lifeguard Training Exercise',\n",
       "       'Lifeguard Exercises', 'Scalloping', 'Jumped into water',\n",
       "       'Playing in the water', 'Feeding sharks & stingrays', 'Fihing',\n",
       "       'Surface Supplied  Diving', 'Floating in inflatable pool ring',\n",
       "       'Fishing for sharks', 'Wing Foil Surfing', 'Boogie Boarding',\n",
       "       'Swimmingq', 'Playing', 'Fishing, fell in water',\n",
       "       'Harassing sharks', 'Squatting in the water',\n",
       "       'Moving captive shark',\n",
       "       \"Jackass Team's publicity stunt for Discovery Channel's Shark Week 2021\",\n",
       "       'Canoeing', 'Parasailing', 'Kite Foiling', 'Baiting sharks',\n",
       "       'Boggie boarding', 'Stand Up Paddleboarding', 'Tagging sharks',\n",
       "       'Body boarding', 'Body surfing', 'Swimming / Kayaking',\n",
       "       'Fell off fishing boat', 'Body Surfing', 'Foil-boarding',\n",
       "       'Surf fishing',\n",
       "       'Fishing / Filming sharks feeding on whale carcass', 'Sightseeing',\n",
       "       'Treading water', 'Skimboarding', 'Body Boarding',\n",
       "       'Stand-Up Paddleboarding', 'Stand-Up Paddle boarding', 'Floating ',\n",
       "       'Swimming after being swept off rocks', 'Feeding sharks',\n",
       "       'Kayaking fishing', 'Swimming/ Treading water',\n",
       "       'Spearfishing / Diving', 'Fishing ', 'Body-surfing',\n",
       "       'Abalone diving', 'Picking opihi', 'Diving in shark tank',\n",
       "       'Paddling an outrigger canoe', 'Diving / Filming',\n",
       "       'Swimming/Standing', 'Putting hand in shark tank', 'Floating',\n",
       "       'Walking', 'Surf-skiing', 'Foilboarding', 'Cleaning fish',\n",
       "       'Fishing / Wading', '2 boats capsized', 'Night bathing',\n",
       "       'Surfing ', 'Kayaking / Fishing', 'Swimming, poaching abalone',\n",
       "       'SUP', 'Touching a shark', 'Attempting to lasso a shark',\n",
       "       'Photo shoot', 'Kakaying', 'Washing hands',\n",
       "       'Grabbing shark for a selfie', 'Not stated', 'Body Recovery',\n",
       "       'Cage Diving', 'Surfng', 'SUP Foil boarding', 'Floating in tube',\n",
       "       'Teasing a shark', 'Diving for beche-de-mer', 'Feeding stingrays?',\n",
       "       'Sea disaster', 'Lobster fishing', 'Swimming / Wading',\n",
       "       'Fishing for shrimp', 'Photographing fish', 'Kayak Fishing',\n",
       "       'Scallop diving on hookah', 'Body boarding ', 'Body surfing?',\n",
       "       'Attempting to rescue a shark', 'Photographing the shark',\n",
       "       'Standing / Snorkeling', 'Hand feeding sharks',\n",
       "       'Sitting in the water', 'Transatlantic Rowing', 'Bodysurfing',\n",
       "       'Rowing', 'Shark fishing', 'Surfing & filming dolphins',\n",
       "       'Swimming after falling overboard', 'Fishing for blue sharks',\n",
       "       'Standing in inner tube', 'Body surfing or Boogie boarding',\n",
       "       'Feeding fish', 'Playing with an air mattress', 'Kite boarding',\n",
       "       'Shark diving', 'Petting a shark', 'Kneeling in the water',\n",
       "       'Fell into the water', 'Shark watching', 'Diving for lobsters',\n",
       "       'Kite Surfing', 'Scuba diving / culling lionfish', 'Kitesurfing',\n",
       "       'Sailing', 'Spearfishing / Free diving',\n",
       "       'Free diving / Photographing pilot whales',\n",
       "       'Filming a documentary',\n",
       "       'Attempting to remove fishing net from submerged object',\n",
       "       'Kiteboarding', 'Diving ', 'Swimming / snorkeling',\n",
       "       'Diving for Abalone', 'Casting a net', 'Marathon swimming',\n",
       "       'Longline fishing for sharks', 'Wrangling a shark',\n",
       "       'Attempting to free the shark', 'Walking in surf', 'Swimming ',\n",
       "       'Swimming & snorkeling', 'Playing in the surf', 'Fly fishing',\n",
       "       \"Fishing - 'tag & release'\",\n",
       "       'Swimming to shore with floatioon devices after boat engine conked out',\n",
       "       'Dragging stranded shark into deeper water', 'Bodyboarding',\n",
       "       'Swimming or boogie boarding', 'Wading or swimming',\n",
       "       'Free diving ', 'Attempting to rescue an injured & beached shark',\n",
       "       'Free diving / spearfishing', 'Crayfishing',\n",
       "       'Diving, feeding sharks',\n",
       "       'Attempting to Kite surf from Egypt to Saudi Arabia',\n",
       "       'Fishing (illegally)', 'Diving, photographing sharks',\n",
       "       'Wade fishing', 'Jumping in the waves', 'Wade Fishing',\n",
       "       'Standing, collecting sea stars', 'Swimming or Snorkeling',\n",
       "       'Kayaking or Wave skiing', 'Jet skiing',\n",
       "       'Standing or boogie boardin', 'Kite Boarding',\n",
       "       'Washing sand off a speared fish', 'Standing, holding shark pup',\n",
       "       'Diving / fishing', 'Wakeboarding', 'Diving for abalone',\n",
       "       'Shark fishing on the Ricardo Astorga',\n",
       "       'Shark fishing on the Don Agustn-VI. ', 'Attempting to fix motor',\n",
       "       'Swimming /  Whale Watching',\n",
       "       'Swimming after boat became disabled', 'Rescuing',\n",
       "       'Measuring sharks', 'Swimming / treading water',\n",
       "       'Surf fishing / wading', 'Spearfishing (free diving)',\n",
       "       'Paddling on kneeboard', 'Swimming to shore from capsized kayak',\n",
       "       'Paddle-boarding',\n",
       "       'Swimming, attempting to rescue a girl  believed to be drowning',\n",
       "       'Washing his feet', 'Paddle-surfing', 'Crawling',\n",
       "       'Diving, but on the surface when bitten by the shark',\n",
       "       'Air Disaster', 'Crabbing', 'Yacht race',\n",
       "       'Sinking of the cargo ship Mark Jason',\n",
       "       'Fishing boat swamped in storm', 'Swimming, towing surfboard',\n",
       "       'Swimming or surfing', 'Rowing an inflatable dinghy',\n",
       "       'Sea Disaster', 'Night diving', 'Free-diving',\n",
       "       'Walking out of the water after surfing', 'Fishing from surfski',\n",
       "       \"Accidentally stood on hooked shark's tail before attempting to gut it \",\n",
       "       'Attempting to chase shark out to sea', 'Fishing for snapper',\n",
       "       'Removing fish from a trap',\n",
       "       'The 426-ton cargo ship Mia, laden with cement, capsized in heavy seas ',\n",
       "       'Wading?', 'Jumping',\n",
       "       'Floating near boat & observing bioluminesce',\n",
       "       'Jumped into the water', 'Surf paddling', 'Murder',\n",
       "       'Removing hook from shark', 'Reviving a sedated shark',\n",
       "       'Shark tagging', 'Swimming / jumping off a jetty',\n",
       "       'Playing on a sandbar', 'Shrimping', 'Swimming / Body Surfing',\n",
       "       'Playing soccer in the water', 'Free diving / modeling',\n",
       "       'Diving / Kissing the shark', 'Lifesaving drill',\n",
       "       'Touching sharks',\n",
       "       'Competing in the Woodvale Atlantic Rowing Race', 'Night Surfing',\n",
       "       'Standing / Surfing', 'Treading water/ Surfing',\n",
       "       'Removing shark from net',\n",
       "       'Boogie boarding, kicked at object in the water',\n",
       "       'Scuba diving in aquarium tank', 'Holding onto an inflatable boat',\n",
       "       'Swimming with boogie board', 'Spearfishing (Free diving)',\n",
       "       \"Crouching in 2' of water\", 'Diving in aquarium display tank',\n",
       "       'Attempting to drive shark away from sailing regatta',\n",
       "       'Fishing from a kayak',\n",
       "       'Swept out to sea by the tsunami, she clung  to a log for 24 hours',\n",
       "       'Scurfing (surfboard being  towed behind a boat)',\n",
       "       'Chumming for white sharks', 'Spearfishing/ filming',\n",
       "       'Diving & fishing with net',\n",
       "       'Wading / fishing & carrying a bag of fish',\n",
       "       'Fishing for squid aboard the trawler Shikishima-Maru when the shark leapt into the boat',\n",
       "       'In water with diving seabirds', 'Swimming, poaching perlemoen',\n",
       "       'Boogie-boarding / swimming', 'Free diving & spearfishing',\n",
       "       'Tandem surfing',\n",
       "       'Five men on makeshift raft after their 10 m fishing boat  capsized and sank in rough seas. Survivors rescued after  7.5 hours in the water',\n",
       "       'Surf skiing', 'Kayaking (returning from spearfishing)',\n",
       "       'Air disaster. Flash Airlines Boeing 737 crashed into the Red Sea',\n",
       "       'Swimming / shipwreck', 'Surfing amid a shoal of sharks',\n",
       "       'Swimming to shore from boat or kayak', 'Sitting on surfboard',\n",
       "       'Wading near a fishing net', 'Wading to shore from his boat',\n",
       "       'Standing, stepped on shark', 'Wade-fishing',\n",
       "       'Swimming, wearing black wetsuit & swim fins',\n",
       "       'Walking, carrying surfboard & stepped on shark',\n",
       "       'Swimming with pod of dolphins', 'Killing  sharks',\n",
       "       'Swimming (using a float)', 'Petting captive sharks', 'Unknown',\n",
       "       \"Fishing, standing in 2' of water\", 'Fishing from Surfboard',\n",
       "       'Boogie boarding or Surfing',\n",
       "       'Wading, when he stepped on the shark', 'Shark Fishing',\n",
       "       'Attempting to retreive a dinghy',\n",
       "       'Snorkeling (filming the sardine run)', 'Floating on a raft',\n",
       "       'Fishing, removing the shark from his line',\n",
       "       'Playing in the surf with his 2 dogs', 'Collecting beche-de-mer',\n",
       "       'Fishing from prawn trawler',\n",
       "       'Scallop diving (using surface-supplied air & a POD) ',\n",
       "       'Fishing (Drowned 2-Apr-2002)',\n",
       "       'Surfing, but standing in water alongside board', 'Body-boarding',\n",
       "       'Swimming /  boogie boarding', 'Capsized fishing boat',\n",
       "       'Kite-Boarding',\n",
       "       'Surfing, fell off surfboard & stepped on the shark.',\n",
       "       'Wreck / Technical diving', 'Walking in shallows',\n",
       "       'Fell off banana boat', 'Floating face-down in knee-deep water',\n",
       "       'Hiking on the beach', 'Spearfishing, carrying his catch',\n",
       "       'Standing alongside surfboard', 'Batin',\n",
       "       'Attempting to catch a crocodile',\n",
       "       \"Sinking of the 40' Esperanza off St. Maartin with 36 refugees on board\",\n",
       "       'Fishing for whiting', 'Swimming back from anchored sailboat',\n",
       "       'Diving for sea urchins', 'Diving (shell maintenance)',\n",
       "       'Shipwrecked', 'Fell onto dead shark', 'Standing / surfing',\n",
       "       'Swimming / Body surfing', 'Conducting research',\n",
       "       'Swimming out to porpoises ',\n",
       "       'Windsurfing, but sitting on his board', 'Surfing / Wading',\n",
       "       'Attempting to illegally enter the USA',\n",
       "       'Spearfishing, holding mesh bag with speared fish',\n",
       "       'Air Disaster - Piper aircraft crashed into the sea, killing all on board',\n",
       "       'Boogie boarding / wading', 'Feeding prawns to captive sharks',\n",
       "       'Canoe with 3 men onboard sank', 'Fishing for tarpon'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"activity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f44a74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surfing',\n",
       " 'swimming',\n",
       " 'fishing',\n",
       " 'spearfishing',\n",
       " 'diving',\n",
       " 'boarding',\n",
       " 'snorkeling',\n",
       " 'wading',\n",
       " 'standing',\n",
       " 'scuba',\n",
       " 'boogie',\n",
       " 'shark',\n",
       " 'kayaking',\n",
       " 'sharks',\n",
       " 'water',\n",
       " 'skiing',\n",
       " 'playing',\n",
       " 'kayak',\n",
       " 'walking',\n",
       " 'feeding']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 Standardize text and remove special characters from the \"activity\" column by converting all text to lowercase, removing leading and trailing whitespace, and replacing any non-alphanumeric characters with an empty string using regular expressions\n",
    "df2[\"activity\"] = df2[\"activity\"].str.lower().str.strip().str.replace(r\"[\\\"']\", '', regex=True)\n",
    "#2 Extract the most common words from the \"activity\" column and create a new column called \"activity_category\" that categorizes each activity based on the presence of these common words (possible mistake: this approach may oversimplify the categorization and may not capture the full context of the activities, leading to potential misclassification.)\n",
    "all_words= re.findall(r'\\w{5,}',' '.join(df2[\"activity\"]))\n",
    "most_common_words = [word for word, count in Counter(all_words).most_common(20)]\n",
    "most_common_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f50028d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['surfing', 'snorkeling', 'diving', 'swimming', 'fishing', 'wading',\n",
       "       'kayaking', 'boogie boarding', 'standing', 'body boarding'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standardize activities\n",
    "selected_values_to_replace = [\"spearfishing\", \"fishing\", \"kayaking\", \"wading\", \"surfing\", \"swimming\", \"diving\", \"skiing\"]\n",
    "\n",
    "for val in selected_values_to_replace: \n",
    "    df2.loc[df2[\"activity\"].str.contains(val, na=False),\"activity\"] = val\n",
    "\n",
    "df2 = df2[df2['activity'] != '']\n",
    "top_10_index = df2['activity'].value_counts().nlargest(10).index\n",
    "df2 = df2[df2['activity'].isin(top_10_index)]\n",
    "df2[\"activity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "939f8e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"activity\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af436693",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_values_to_replace = ['spearfishing', 'paddleboarding', 'snorkeling','kayaking', 'skiing', 'rowing', 'boarding','swimming', 'fishing', 'diving', 'wading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ce464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option of creating a new column with categorized values\n",
    "\n",
    "def clean_activity_fixed(text):\n",
    "    text = str(text).lower()\n",
    "    # Check for the most specific terms first\n",
    "    if 'spearfishing' in text: return 'spearfishing'\n",
    "    if 'paddleboarding' in text: return 'paddleboarding'\n",
    "    if 'fishing' in text: return 'fishing'\n",
    "    if 'surfing' in text: return 'surfing'\n",
    "    # ... add the rest of your list here\n",
    "    return text # if no match, keep the original (or return 'other')\n",
    "\n",
    "df2['activity'] = df2['activity'].apply(clean_activity_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ceba18",
   "metadata": {},
   "source": [
    "INJURY  *check code to ensure python reads both bodyparts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "00d0c8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "injury\n",
       "FATAL                                                                       178\n",
       "Foot bitten                                                                  51\n",
       "Left foot bitten                                                             34\n",
       "No injury                                                                    27\n",
       "Leg bitten                                                                   24\n",
       "                                                                           ... \n",
       "Torso nipped                                                                  1\n",
       "Left arm and leg injured                                                      1\n",
       "Injuries to right calf and thigh                                              1\n",
       "Body washed up on beach with signs of shark attack bites and leg missing      1\n",
       "No injury to occupant; shark bit propeller                                    1\n",
       "Name: count, Length: 1760, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"injury\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b36ae12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['injury'] = df2['injury'].fillna('').str.strip().str.lower().str.replace(r\"[\\\"']\", '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c68b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>attack_type</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>activity</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>injury</th>\n",
       "      <th>species</th>\n",
       "      <th>body_part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20th January</td>\n",
       "      <td>2026</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Point Plomber North of Port Macquarie</td>\n",
       "      <td>surfing</td>\n",
       "      <td>Paul Zvirdinas</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>Minor cuts and abrasions</td>\n",
       "      <td>Bull shark</td>\n",
       "      <td>Multiple/Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19th January</td>\n",
       "      <td>2026</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Dee Why</td>\n",
       "      <td>surfing</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>None reported damage to board</td>\n",
       "      <td>Bull shark</td>\n",
       "      <td>No Body Part (Equipment/None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19th January</td>\n",
       "      <td>2026</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>North Steyne</td>\n",
       "      <td>surfing</td>\n",
       "      <td>Andre de Ruyter</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>Serious Leg injuries</td>\n",
       "      <td>5m shark species not determined</td>\n",
       "      <td>Lower Extremity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10th January</td>\n",
       "      <td>2026</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Avalon Beach</td>\n",
       "      <td>surfing</td>\n",
       "      <td>Paul Stanton</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>Puncture mark to left thumb</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Multiple/Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8th January</td>\n",
       "      <td>2026</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>US Virgin Islands</td>\n",
       "      <td>Fredricksted Island St Croix</td>\n",
       "      <td>Dorsch Beach</td>\n",
       "      <td>snorkeling</td>\n",
       "      <td>Arlene Lillis</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>Left arm torn off in the attack below the elbow</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Upper Extremity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  year attack_type            country  \\\n",
       "0  20th January  2026  Unprovoked          Australia   \n",
       "1  19th January  2026  Unprovoked          Australia   \n",
       "2  19th January  2026  Unprovoked          Australia   \n",
       "4  10th January  2026  Unprovoked          Australia   \n",
       "5   8th January  2026  Unprovoked  US Virgin Islands   \n",
       "\n",
       "                          state                               location  \\\n",
       "0                           NSW  Point Plomber North of Port Macquarie   \n",
       "1                           NSW                                Dee Why   \n",
       "2                           NSW                          North Steyne    \n",
       "4                           NSW                           Avalon Beach   \n",
       "5  Fredricksted Island St Croix                           Dorsch Beach   \n",
       "\n",
       "     activity             name sex age  \\\n",
       "0     surfing   Paul Zvirdinas   M  39   \n",
       "1     surfing          Unknown   M  11   \n",
       "2     surfing  Andre de Ruyter   M  27   \n",
       "4     surfing     Paul Stanton   M   ?   \n",
       "5  snorkeling    Arlene Lillis   F  56   \n",
       "\n",
       "                                             injury  \\\n",
       "0                         Minor cuts and abrasions    \n",
       "1                     None reported damage to board   \n",
       "2                              Serious Leg injuries   \n",
       "4                       Puncture mark to left thumb   \n",
       "5  Left arm torn off in the attack below the elbow    \n",
       "\n",
       "                           species                      body_part  \n",
       "0                       Bull shark           Multiple/Unspecified  \n",
       "1                       Bull shark  No Body Part (Equipment/None)  \n",
       "2  5m shark species not determined                Lower Extremity  \n",
       "4                          Unknown           Multiple/Unspecified  \n",
       "5                         Unknown                 Upper Extremity  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract body part from the injury description (possible mistake: python will only return the first match it finds, so if there are multiple body parts mentioned, it will only categorize based on the first one. This could lead to misclassification if the most relevant body part is not mentioned first in the injury description.)\n",
    "def extract_body_part(text):\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Define body part categories and their related keywords\n",
    "    if any(word in text for word in ['leg', 'thigh', 'calf', 'knee', 'foot', 'feet', 'ankle', 'toe']):\n",
    "        return 'Lower Extremity'\n",
    "    \n",
    "    elif any(word in text for word in ['arm', 'hand', 'finger', 'wrist', 'elbow', 'shoulder', 'forearm']):\n",
    "        return 'Upper Extremity'\n",
    "    \n",
    "    elif any(word in text for word in ['torso', 'chest', 'back', 'abdomen', 'trunk']):\n",
    "        return 'Torso'\n",
    "    \n",
    "    elif any(word in text for word in ['head', 'face', 'neck', 'scalp']):\n",
    "        return 'Head/Neck'\n",
    "    \n",
    "    elif any(word in text for word in ['no injury', 'board', 'kayak', 'boat', 'propeller']):\n",
    "        return 'No Body Part (Equipment/None)'\n",
    "        \n",
    "    else:\n",
    "        return 'Multiple/Unspecified'\n",
    "\n",
    "# Apply to your DataFrame\n",
    "df2['body_part'] = df2['injury'].apply(extract_body_part)\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77013225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "White shark                                        93\n",
       "Bull shark                                         51\n",
       "Tiger shark                                        48\n",
       "Shark involvement not confirmed                    46\n",
       "4' shark                                           31\n",
       "                                                   ..\n",
       "Tiger shark, 3.5 m                                  1\n",
       "3.5 to 4 m shark                                    1\n",
       "2 m to  3 m shark                                   1\n",
       "Bull shark, 1.3 m                                   1\n",
       "Shortfin mako shark, 3 m to 3.4 m [10' to 11']      1\n",
       "Name: count, Length: 805, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"species\"].value_counts() #3 categories only, because rest of data to unconcrete? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b58b9",
   "metadata": {},
   "source": [
    "COUNTRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d87ecf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_formatting(df):\n",
    "    def fix_name(x):\n",
    "        # 1. Skip if it's not text (handles NaN/empty cells)\n",
    "        if not isinstance(x, str):\n",
    "            return x\n",
    "        \n",
    "        # 2. Clean whitespace and make lowercase for checking\n",
    "        name = x.strip().lower()\n",
    "        \n",
    "        # 3. Handle specific abbreviations (Force Uppercase)\n",
    "        abbreviations = ['usa', 'uk', 'uae']\n",
    "        if name in abbreviations:\n",
    "            return name.upper()\n",
    "        \n",
    "        # 4. Handle everything else (Capitalize Every Word)\n",
    "        # .title() turns \"south africa\" into \"South Africa\"\n",
    "        return name.title()\n",
    "\n",
    "    df['country'] = df['country'].apply(fix_name)\n",
    "    return df\n",
    "\n",
    "# Apply the change\n",
    "df2 = country_formatting(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5fd43f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"country\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc9e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plan:\n",
    "#categorize: activity \n",
    "#Filtrar datos?\n",
    "#groupby\n",
    "#we want to create gear for male/or fewmale depending on the activity perfomed, there are diferent product needs\n",
    "# as a marketing campaign, we want to know, how many provoked incidents there are and if these are related with the activity types\n",
    "\n",
    "#Bonus: \n",
    "#to which markets (countries) we can sell or products based on incident numbers\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
